{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_layer_old(l_type, units, prev_layer, prev_layer_string, gpu=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if l_type == 'lstm':\n",
    "        if gpu:\n",
    "            string = \"\\nx = tf.keras.layers.CuDNNLSTM(units=\"+str(units)+\")\"+prev_layer_string\n",
    "            x = tf.keras.layers.CuDNNLSTM(units=units)(prev_layer)\n",
    "        else:\n",
    "            string = \"\\nx = tf.keras.layers.LSTM(units=\"+str(units)+\")\"+prev_layer_string\n",
    "            x = tf.keras.layers.LSTM(units=units)(prev_layer)\n",
    "    elif l_type == 'gru':\n",
    "        if gpu:\n",
    "            string = \"\\nx = tf.keras.layers.CuDNNGRU(units=\"+str(units)+\")\"+prev_layer_string\n",
    "            x = tf.keras.layers.CuDNNGRU(units=units)(prev_layer)\n",
    "        else:\n",
    "            string = \"\\nx = tf.keras.layers.GRU(units=\"+str(units)+\")\"+prev_layer_string\n",
    "            x = tf.keras.layers.GRU(units=units)(prev_layer)\n",
    "    \n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_layer(l_type, units, prev_layer, prev_layer_string, usel_type=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if 'lstm' in l_type:\n",
    "        if usel_type:\n",
    "            string = \"\\n\"+l_type+\" = tf.keras.layers.LSTM(units=\"+str(units)+\",return_sequences=True)\"+prev_layer_string\n",
    "        else:\n",
    "            string = \"\\nx = tf.keras.layers.LSTM(units=\"+str(units)+\")\"+prev_layer_string\n",
    "        x = tf.keras.layers.LSTM(units=units,return_sequences=True)(prev_layer)\n",
    "    elif 'gru' in l_type:\n",
    "        if usel_type:\n",
    "            string = \"\\n\"+l_type+\" = tf.keras.layers.GRU(units=\"+str(units)+\")\"+prev_layer_string\n",
    "        else:\n",
    "            string = \"\\nx = tf.keras.layers.GRU(units=\"+str(units)+\",return_sequences=True)\"+prev_layer_string\n",
    "        x = tf.keras.layers.GRU(units=units,return_sequences=True)(prev_layer)\n",
    "    \n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_layer(l_type, units, prev_layer, prev_layer_string, usel_type=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if '1d' in l_type:\n",
    "        if usel_type:\n",
    "            string = \"\\n\"+l_type+\" = tf.keras.layers.Conv1D(filters=\" + str(units[0]) + \",kernel_size=\" + str(units[1]) + \")\" + prev_layer_string\n",
    "        else:\n",
    "            string = \"\\nx = tf.keras.layers.Conv1D(filters=\" + str(units[0]) + \",kernel_size=\" + str(units[1]) + \")\" + prev_layer_string\n",
    "        x = tf.keras.layers.Conv1D(filters=units[0], kernel_size=units[1])(prev_layer)\n",
    "\n",
    "    elif '2d' in l_type:\n",
    "        if usel_type:\n",
    "            string = \"\\n\"+l_type+\" = tf.keras.layers.Conv2D(filters=\" + str(units[0]) + \",kernel_size=\" + str(units[1]) + \")\" + prev_layer_string\n",
    "        else:\n",
    "            string = \"\\nx = tf.keras.layers.Conv2D(filters=\" + str(units[0]) + \",kernel_size=\" + str(units[1]) + \")\" + prev_layer_string\n",
    "        x = tf.keras.layers.Conv2D(filters=n_units[i][0], kernel_size=n_units[i][1])(prev_layer)\n",
    "\n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_layer(l_type, units, prev_layer, prev_layer_string, activ=None, usel_type=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if usel_type:\n",
    "        string += \"\\n\"+l_type+\" = tf.keras.layers.Dense(units=\"+str(units)\n",
    "    else:\n",
    "        string += \"\\nx = tf.keras.layers.Dense(units=\"+str(units)\n",
    "    if activ:\n",
    "        string += \", activation=\"+str(activ)\n",
    "        x = tf.keras.layers.Dense(units=units, activation=activ)(prev_layer)\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(units=units)(prev_layer)\n",
    "    string += \")\"+prev_layer_string\n",
    "    \n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_layer(l_type, input_tensors, input_layer_names, usel_type=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if usel_type:\n",
    "        string += \"\\n\"+l_type+\" = tf.keras.layers.Concatenate(axis=1)\"+input_layer_names\n",
    "    else:\n",
    "        string += \"\\nx = tf.keras.layers.Concatenate(axis=1)\"+input_layer_names\n",
    "    x = tf.keras.layers.Concatenate(axis=1)(input_tensors)\n",
    "    \n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_add_layer(l_type, input_tensors, input_layer_names, usel_type=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if usel_type:\n",
    "        string += \"\\n\"+l_type+\" = tf.keras.layers.Add()\"+input_layer_names\n",
    "    else:\n",
    "        string += \"\\nx = tf.keras.layers.Add()\"+input_layer_names\n",
    "    x = tf.keras.layers.Add()(input_tensors)\n",
    "    \n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiply_layer(l_type, input_tensors, input_layer_names, usel_type=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if usel_type:\n",
    "        string += \"\\n\"+l_type+\" = tf.keras.layers.Multiply()\"+input_layer_names\n",
    "    else:\n",
    "        string += \"\\nx = tf.keras.layers.Multiply()\"+input_layer_names\n",
    "    x = tf.keras.layers.Multiply()(input_tensors)\n",
    "    \n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flatten_layer(l_type, input_tensors, input_layer_names, usel_type=False):\n",
    "    string = \"\"\n",
    "    x = None\n",
    "    if usel_type:\n",
    "        string += \"\\n\"+l_type+\" = tf.keras.layers.Flatten()\"+input_layer_names\n",
    "    else:\n",
    "        string += \"\\nx = tf.keras.layers.Flatten()\"+input_layer_names\n",
    "    x = tf.keras.layers.Flatten()(input_tensors)\n",
    "    \n",
    "    return string, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = {\n",
    "    'input':{\n",
    "        'num_layers':1,\n",
    "        'shape': (10,1)\n",
    "    },\n",
    "    'conv1d':{\n",
    "        'num_layers':2,\n",
    "        'num_units': [[32,3],[32,5]]\n",
    "    },\n",
    "    'lstm':{\n",
    "        'num_layers':1, \n",
    "        'num_units': [32]\n",
    "    },\n",
    "    'dense':{\n",
    "        'num_layers':4, \n",
    "        'num_units': [128, 64, 32, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_build_simple_sequential(layer_dict):\n",
    "    \n",
    "    code_string = \"\"\n",
    "    prev_layer = None\n",
    "    \n",
    "    for l_type in layer_dict.keys():\n",
    "        \n",
    "        if l_type == 'input':\n",
    "            shape = layer_dict[l_type]['shape']\n",
    "            code_string += \"inp = tf.keras.layers.Input(shape=\"+str(shape)+\")\"\n",
    "            inp = tf.keras.layers.Input(shape=shape)\n",
    "            prev_layer = '(inp)'\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            n_layers = layer_dict[l_type]['num_layers']\n",
    "            n_units = layer_dict[l_type]['num_units']\n",
    "            \n",
    "            for i in range(n_layers):\n",
    "                \n",
    "                if l_type in ['lstm', 'gru']:\n",
    "                    if prev_layer == '(inp)':\n",
    "                        string, x = get_rnn_layer(l_type, n_units[i], inp, prev_layer)\n",
    "                    else:\n",
    "                        string, x = get_rnn_layer(l_type, n_units[i], x, prev_layer)\n",
    "                    code_string += string\n",
    "                \n",
    "                elif l_type == 'dense':\n",
    "                    code_string += \"\\nx = tf.keras.layers.Dense(units=\"+str(n_units[i])+\")\"+prev_layer\n",
    "                    \n",
    "                    if prev_layer == '(inp)':\n",
    "                        x = tf.keras.layers.Dense(units=n_units[i])(inp)\n",
    "                    \n",
    "                    else:\n",
    "                        x = tf.keras.layers.Dense(units=n_units[i])(x)\n",
    "                \n",
    "                elif 'conv' in l_type:\n",
    "                    if prev_layer == '(inp)':\n",
    "                        string, x = get_cnn_layer(l_type, n_units[i], inp, prev_layer)\n",
    "                    else:\n",
    "                        string, x = get_cnn_layer(l_type, n_units[i], x, prev_layer)\n",
    "                    code_string += string\n",
    "                                            \n",
    "                prev_layer = '(x)'\n",
    "        \n",
    "    code_string += \"\\nmodel = tf.keras.models.Model(inputs=[inp], outputs=[x], name='Base')\"\n",
    "    model = tf.keras.models.Model(inputs=[inp], outputs=[x], name='Base')\n",
    "    \n",
    "    return code_string, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 23:40:22.718391 140606139144000 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fe075532cc0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "code, model = keras_build_simple_sequential(layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp = tf.keras.layers.Input(shape=(10, 1))\n",
      "x = tf.keras.layers.Conv1D(filters=32,kernel_size=3)(inp)\n",
      "x = tf.keras.layers.Conv1D(filters=32,kernel_size=5)(x)\n",
      "x = tf.keras.layers.LSTM(units=32)(x)\n",
      "x = tf.keras.layers.Dense(units=128)(x)\n",
      "x = tf.keras.layers.Dense(units=64)(x)\n",
      "x = tf.keras.layers.Dense(units=32)(x)\n",
      "x = tf.keras.layers.Dense(units=1)(x)\n",
      "model = tf.keras.models.Model(inputs=[inp], outputs=[x], name='Base')\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Base\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 10, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 8, 32)             128       \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 4, 32)             5152      \n",
      "_________________________________________________________________\n",
      "unified_lstm_19 (UnifiedLSTM (None, 4, 32)             8320      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4, 128)            4224      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4, 64)             8256      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4, 32)             2080      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4, 1)              33        \n",
      "=================================================================\n",
      "Total params: 28,193\n",
      "Trainable params: 28,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Parallel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer names are important to build the DAG\n",
    "layer_dict = {\n",
    "    'num_branches' : 11,\n",
    "    'branches' : {\n",
    "        'branch1': {\n",
    "            'inputs': ['input_1'],\n",
    "            'output': ['conv_1d_1']\n",
    "        },\n",
    "        'branch2': {\n",
    "            'inputs': ['conv_1d_1'],\n",
    "            'output': ['lstm_1']\n",
    "        },\n",
    "        'branch3': {\n",
    "            'inputs': ['conv_1d_1','lstm_1'],\n",
    "            'output': ['concat_1']\n",
    "        },\n",
    "        'branch4': {\n",
    "            'inputs': ['conv_1d_1','lstm_1'],\n",
    "            'output': ['add_1']\n",
    "        },\n",
    "        'branch5': {\n",
    "            'inputs': ['conv_1d_1','lstm_1'],\n",
    "            'output': ['multiply_1']\n",
    "        },\n",
    "        'branch6': {\n",
    "            'inputs': ['concat_1','add_1', 'multiply_1'],\n",
    "            'output': ['concat_2']\n",
    "        },\n",
    "        'branch7':{\n",
    "            'inputs': ['concat_2'],\n",
    "            'output': ['flatten_1']\n",
    "        },\n",
    "        'branch8': {\n",
    "            'inputs': ['flatten_1'],\n",
    "            'output': ['dense_1']\n",
    "        },\n",
    "        'branch9': {\n",
    "            'inputs': ['dense_1'],\n",
    "            'output': ['dense_2']\n",
    "        },\n",
    "        'branch10': {\n",
    "            'inputs': ['dense_2'],\n",
    "            'output': ['dense_3']\n",
    "        },\n",
    "        'branch11': {\n",
    "            'inputs': ['dense_3'],\n",
    "            'output': ['output_1']\n",
    "        }\n",
    "    },\n",
    "    'layer_units' : {\n",
    "        'input_1' : (10,1),\n",
    "        'conv_1d_1' : [32, 3],\n",
    "        'lstm_1' : [32],\n",
    "        'dense_1' : [128],\n",
    "        'dense_2' : [128],\n",
    "        'dense_3' : [128],\n",
    "        'output_1' : [1],\n",
    "    },\n",
    "    'layer_activations' : {\n",
    "        'dense_1' : 'relu',\n",
    "        'dense_2' : 'relu',\n",
    "        'dense_3' : 'relu'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_build_simple_parallel(layer_dict):\n",
    "    n_branches = layer_dict['num_branches']\n",
    "    branches = layer_dict['branches']\n",
    "    units = layer_dict['layer_units']\n",
    "    acts = layer_dict['layer_activations']\n",
    "\n",
    "    ip = [x for x in units.keys() if 'input' in x]\n",
    "    num_inputs = len(ip)\n",
    "    op = [x for x in units.keys() if 'output' in x]\n",
    "    num_outputs = len(op)\n",
    "    \n",
    "    code_string = \"\"\n",
    "    prev_layer = None\n",
    "    tensors = {}\n",
    "    for i in range(num_inputs):\n",
    "        var_name = \"input_\"+str(i+1)\n",
    "        code_string += var_name+\" = tf.keras.layers.Input(shape=\"+str(units[var_name])+\")\"\n",
    "        tensors[var_name] = tf.keras.layers.Input(shape=units[var_name])\n",
    "\n",
    "    for branch in branches.keys():\n",
    "        l_type = branches[branch]['output'][0]\n",
    "        try:\n",
    "            n_units = units[l_type]\n",
    "        except:\n",
    "            n_units = None\n",
    "        try:    \n",
    "            activs = acts[l_type]\n",
    "        except:\n",
    "            activs = None\n",
    "\n",
    "        if 'conv' in l_type:\n",
    "            string, tensors[l_type] = get_cnn_layer(l_type, n_units, tensors[branches[branch]['inputs'][0]], \"(\"+branches[branch]['inputs'][0]+\")\", True)\n",
    "            code_string += string\n",
    "        elif any(lyrs in l_type for lyrs in ['lstm','gru']):\n",
    "            string, tensors[l_type] = get_rnn_layer(l_type, n_units[0], tensors[branches[branch]['inputs'][0]], \"(\"+branches[branch]['inputs'][0]+\")\", True)\n",
    "            code_string += string\n",
    "        elif 'dense' in l_type or 'output' in l_type:\n",
    "            string, tensors[l_type] = get_dense_layer(l_type, n_units[0], tensors[branches[branch]['inputs'][0]], \"(\"+branches[branch]['inputs'][0]+\")\", activs, True)\n",
    "            code_string += string\n",
    "        elif 'concat' in l_type:\n",
    "            string, tensors[l_type] = get_concat_layer(l_type, [tensors[k] for k in branches[branch]['inputs']], \"(\"+str(branches[branch]['inputs'])+\")\", True)\n",
    "            code_string += string\n",
    "        elif 'add' in l_type:\n",
    "            string, tensors[l_type] = get_add_layer(l_type, [tensors[k] for k in branches[branch]['inputs']], \"(\"+str(branches[branch]['inputs'])+\")\", True)\n",
    "            code_string += string\n",
    "        elif 'multiply' in l_type:\n",
    "            string, tensors[l_type] = get_multiply_layer(l_type, [tensors[k] for k in branches[branch]['inputs']], \"(\"+str(branches[branch]['inputs'])+\")\", True)\n",
    "            code_string += string\n",
    "        elif 'flatten' in l_type:\n",
    "            string, tensors[l_type] = get_flatten_layer(l_type, tensors[branches[branch]['inputs'][0]], \"(\"+str(branches[branch]['inputs'])+\")\", True)\n",
    "            code_string += string\n",
    "\n",
    "    code_string += \"\\nmodel = tf.keras.models.Model(inputs=\"+str([tensors.get(key) for key in ip])+\", outputs=\"+str([tensors.get(key) for key in op])+\", name='Parallel_Base')\"\n",
    "    model = tf.keras.models.Model(inputs=[tensors.get(key) for key in ip], outputs=[tensors.get(key) for key in op], name=\"Parallel_Base\")\n",
    "    \n",
    "    return code_string, tensors, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 23:48:59.808893 140333081143104 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fa15a8f2c18>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "code, tensors, model = keras_build_simple_parallel(layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 = tf.keras.layers.Input(shape=(10, 1))\n",
      "conv_1d_1 = tf.keras.layers.Conv1D(filters=32,kernel_size=3)(input_1)\n",
      "lstm_1 = tf.keras.layers.LSTM(units=32,return_sequences=True)(conv_1d_1)\n",
      "concat_1 = tf.keras.layers.Concatenate(axis=1)(['conv_1d_1', 'lstm_1'])\n",
      "add_1 = tf.keras.layers.Add()(['conv_1d_1', 'lstm_1'])\n",
      "multiply_1 = tf.keras.layers.Multiply()(['conv_1d_1', 'lstm_1'])\n",
      "concat_2 = tf.keras.layers.Concatenate(axis=1)(['concat_1', 'add_1', 'multiply_1'])\n",
      "flatten_1 = tf.keras.layers.Flatten()(['concat_2'])\n",
      "dense_1 = tf.keras.layers.Dense(units=128, activation=relu)(flatten_1)\n",
      "dense_2 = tf.keras.layers.Dense(units=128, activation=relu)(dense_1)\n",
      "dense_3 = tf.keras.layers.Dense(units=128, activation=relu)(dense_2)\n",
      "output_1 = tf.keras.layers.Dense(units=1)(dense_3)\n",
      "model = tf.keras.models.Model(inputs=[<tf.Tensor 'input_1:0' shape=(None, 10, 1) dtype=float32>], outputs=[<tf.Tensor 'dense_3/BiasAdd:0' shape=(None, 1) dtype=float32>], name='Parallel_Base')\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Parallel_Base\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 8, 32)        128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)      (None, 8, 32)        8320        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 32)       0           conv1d[0][0]                     \n",
      "                                                                 unified_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 32)        0           conv1d[0][0]                     \n",
      "                                                                 unified_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 8, 32)        0           conv1d[0][0]                     \n",
      "                                                                 unified_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32)       0           concatenate[0][0]                \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          131200      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 172,801\n",
      "Trainable params: 172,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
